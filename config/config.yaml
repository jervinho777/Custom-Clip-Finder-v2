# Custom Clip Finder v2 Configuration
# API Keys are loaded from .env file

models:
  # Stage 1: DISCOVER - 5 AI Ensemble (verified working models from V1)
  discovery:
    - provider: anthropic
      model: claude-opus-4-20250514  # Opus 4.5 ðŸ’Ž
      role: synthesis
    - provider: openai
      model: gpt-5.2  # GPT-5.2 ðŸ”¥
      role: pattern_recognition
    - provider: google
      model: gemini-3.0-pro  # Gemini 3.0 Pro
      role: context_analysis
    - provider: xai
      model: grok-4-1-fast-reasoning  # Grok 4.1 ðŸš€
      role: edge_cases
    - provider: deepseek
      model: deepseek-chat  # DeepSeek V3.2
      role: cost_efficient

  # Stage 2: COMPOSE - Debate
  compose:
    primary: claude-opus-4-20250514  # Opus for quality
    fallback: claude-sonnet-4-5-20250929  # Sonnet as fallback
    rounds: 3

  # Stage 3: VALIDATE - Final Decision  
  validate:
    model: claude-opus-4-20250514  # Opus for final decisions
    # Sonnet fÃ¼r schnellere Validierung wenn Budget knapp
    fast_model: claude-sonnet-4-5-20250929

brain:
  vector_store_path: ./brain/vector_store
  principles_path: ./brain/PRINCIPLES.json
  update_schedule: weekly

pipeline:
  # Thresholds
  min_moment_duration: 20  # seconds
  max_moment_duration: 90  # seconds
  min_consensus_votes: 3   # of 5 AIs
  quality_threshold: 80    # for pre-screening

export:
  formats:
    - mp4
    - xml
    - json
  output_dir: ./data/output

# Cost Mode: quality, balanced, fast
mode: balanced

