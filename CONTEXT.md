# Custom Clip Finder - Projekt Context

## Was es tut
Extrahiert virale Momente aus langen Videos mittels optimierter V4 Pipeline mit 9 Stages + Godmode Evaluation. Verwendet Multi-AI Ensemble (GPT, Claude, Gemini, DeepSeek, Grok) f√ºr Pattern-Erkennung und Multi-Level-Optimierung.

## Aktuelle Architektur (V4 Pipeline)

### Pipeline-Stages:
1. **Stage 0: Coarse Viral Scan** - Schnelle, breite Suche nach viralen Potenzialen (20-30 Seeds, pre-scored)
2. **Stage 1: Batch Refinement** - Optimale Grenzen finden (20-30 refined moments, batched)
3. **Stage 1.75: Open Loop Bridging** - Br√ºckt kleine L√ºcken bei offenen Loops (<5s, rule-based)
4. **Stage 2: Conditional Restructure** - Restrukturiert nur Momente die es brauchen (~60%, conditional)
5. **Stage 2.5: Learning-Based Cuts** - Optimiert Duration basierend auf 175 analysierten Clips
6. **Stage 2.6: Cross-Moment Hook Extraction** - Findet st√§rkste Hooks im gesamten Video
7. **Stage 2.7: Micro-Level Text Optimization** - Wort-Level Pr√§zision (5-10% Reduktion)
8. **Stage 2.8: Dramatic Structure & Timing** - Strategische Pausen f√ºr Drama
9. **Stage 2.9: Payoff Isolation** - Finale Polierung, isoliert Money Shot (‚è≥ noch nicht implementiert)
10. **Godmode: Batched Premium Evaluation** - Finale Opus 4 Evaluation (40+ Score)

### Prinzipien-basiert (nicht rigid):
- COMPLETENESS for what it IS
- NATURAL BOUNDARIES
- EMOTIONAL INTENSITY
- PATTERN INTERRUPTS
- FORMAT FLEXIBILITY
- CONTEXT AWARENESS

## Haupt-Entry-Points
- `create_clips_v4_integrated.py` - Main V4 Pipeline (9 Stages + Godmode)
- `test_2stage_cached.py` - Cached Pipeline Test
- `test_stage_2_5.py` - Isolierter Test f√ºr Learning-Based Cuts
- `test_stage_1_75.py` - Isolierter Test f√ºr Open Loop Bridging

## Learnings-System
- **Analyse:** `analyze_and_learn_v2.py` - Analysiert virale Clips (175+ analysiert)
- **Merge:** `master_learnings_v2.py` - Zentralisiert alle Learnings
- **Nutzung:** `get_learnings_for_prompt()` - Injiziert Learnings in AI-Prompts
- **Datenbank:** `data/MASTER_LEARNINGS.json` - Zentrale Learnings-Datenbank

## Self-Learning System (NEU! üß†)
- **Pattern Analyzer:** `viral_pattern_analyzer.py` - Analysiert isolierte Clips + Transformation Pairs
- **Principle Synthesizer:** `synthesize_principles.py` - Synthetisiert Master Principles (VIRAL_PRINCIPLES.json)
- **Auto-Update:** `update_brain.py` / `auto_update_brain.sh` - Kontinuierliche Verbesserung
- **Composer Integration:** `create_clips_v4_integrated.py` l√§dt automatisch VIRAL_PRINCIPLES.json
- **Master Brain:** `data/learnings/VIRAL_PRINCIPLES.json` - Zentrale Prinzipien-Datenbank (self-learning!)

## Was funktioniert ‚úÖ
- ‚úÖ V4 Pipeline mit 9 Stages (8 implementiert, 1 pending)
- ‚úÖ Caching System (Transcripts + Pipeline-Outputs, 85% Effizienz)
- ‚úÖ Multi-AI Ensemble (Consensus Engine)
- ‚úÖ Open Loop Bridging (Stage 1.75) - Rule-based, $0 Cost
- ‚úÖ Stage 2.5: Viral Composition - Holistic Multi-AI Optimization (ersetzt 5 separate stages)
- ‚úÖ Cross-Moment Hook Extraction (Stage 2.6) - Findet Hooks aus anderen Momenten
- ‚úÖ Micro-Level Text Optimization (Stage 2.7) - Wort-Level Pr√§zision
- ‚úÖ Dramatic Timing (Stage 2.8) - Strategische Pausen
- ‚úÖ Batched Godmode Evaluation (Opus 4)
- ‚úÖ Principle-based Approach (nicht rigid)
- ‚úÖ Batch-Verarbeitung (kosteneffizient, 80% Savings)
- ‚úÖ Conditional Processing (nur verarbeiten was n√∂tig ist)
- ‚úÖ Premiere XML Export
- ‚úÖ Comprehensive Documentation (`SYSTEM_OVERVIEW.md`, `PROJECT_HISTORY.md`)
- ‚úÖ **Self-Learning System** - Viral Pattern Analyzer + Principle Synthesizer (NEU!)
- ‚úÖ **Auto-Update Workflow** - Kontinuierliche Verbesserung durch neue Daten (NEU!)
- ‚úÖ **Principle-based Analysis** - `analyze_restructures_v1.py` gibt Prinzipien statt rigider Regeln aus (NEU!)

## Was NICHT funktioniert / Probleme ‚ö†Ô∏è
- ‚ö†Ô∏è **Kosten:** ~$9.20 pro Video (Stage 2.5 konsolidiert, aber noch nicht getestet)
- ‚ö†Ô∏è **Qualit√§t:** Godmode Scores noch nicht vollst√§ndig getestet (Ziel: 46-50/50)
- ‚ö†Ô∏è **Stage 2.9:** Payoff Isolation noch nicht implementiert (‚è≥ pending)
- ‚ö†Ô∏è **Redundanz:** Viele alte Versionen (v1, v2, v3) noch vorhanden
- ‚ö†Ô∏è **Test-Coverage:** Pipeline nur auf Dieter Lange getestet, nicht auf diverse Content-Typen
- ‚ö†Ô∏è **Export:** Export-Funktion wurde angepasst, aber noch nicht mit vollst√§ndiger Pipeline getestet
- ‚ö†Ô∏è **Self-Learning System:** VIRAL_PRINCIPLES.json noch nicht initial trainiert (muss `viral_pattern_analyzer.py` ausf√ºhren)
- ‚ö†Ô∏è **API Refusals:** Initiale Prompt-Versionen in `synthesize_principles.py` f√ºhrten zu Refusals (gel√∂st durch Vereinfachung)

## N√§chste Schritte (Priorit√§t)
1. [ ] **Self-Learning System initialisieren** - `python viral_pattern_analyzer.py` ausf√ºhren (erstellt VIRAL_PRINCIPLES.json)
2. [ ] **Principle Synthesizer testen** - `python synthesize_principles.py` validieren (sollte ohne Refusals laufen)
3. [ ] **Vollst√§ndiger Pipeline-Test** - Dieter Lange end-to-end mit neuen Principles ($9.20, validiere Scores)
4. [ ] **Stage 2.9 implementieren** - Payoff Isolation (30-45 min, +$0.50/video)
5. [ ] **Diverse Content-Tests** - Podcast, Educational, Stage Talk, Interview (5 Videos, $46.00)
6. [ ] **Auto-Update Workflow testen** - Neue Clips hinzuf√ºgen ‚Üí `./auto_update_brain.sh` ‚Üí Brain verbessert sich
7. [ ] **Projekt aufr√§umen** - Alte Versionen archivieren/l√∂schen
8. [ ] **Comprehensive Logging** - Stage-Level Visibility f√ºr Debugging

## Entscheidungen (Aktuell)
| Datum | Entscheidung | Warum |
|-------|--------------|-------|
| 2024-12-25 | V4 Pipeline mit 9 Stages implementiert | Multi-Level-Optimierung f√ºr viral-ready Clips |
| 2024-12-25 | Principle-based statt rigid rules | Bessere Anpassungsf√§higkeit an verschiedene Formate |
| 2024-12-25 | Batch-Verarbeitung √ºberall | Kostenreduktion (80% Savings) |
| 2024-12-25 | Single-Gate Godmode (nicht Two-Gate) | Niedrigere False-Negative-Rate (10% vs 19%) |
| 2024-12-25 | Multi-Level-Optimization (Stages 2.5-2.9) | Viral Clips werden komponiert, nicht nur gefunden |
| 2024-12-25 | Comprehensive Documentation erstellt | Vollst√§ndiges System-Verst√§ndnis |
| 2025-01-02 | **Self-Learning System implementiert** | Kontinuierliche Verbesserung durch neue Daten, kein statisches System |
| 2025-01-02 | **Stage 2.5 zu "Viral Composition" konsolidiert** | 5 separate stages ‚Üí 1 holistic stage (52% Kostenersparnis, intelligentere Optimierung) |
| 2025-01-02 | **Principle-based Analysis Output** | `analyze_restructures_v1.py` gibt Prinzipien statt rigider Regeln aus |
| 2025-01-02 | **Direct Anthropic API in Synthesizer** | Keine komplexen Dependencies, einfachere Fehlerbehandlung |
| 2025-01-02 | **Simplified Prompts (nur Stats)** | Vermeidet API Refusals, k√ºrzere Prompts, effizienter |

## Was ich behalten will
- ‚úÖ 5-AI Ensemble Logik (Consensus Engine)
- ‚úÖ Caching System (Transcripts + Pipeline)
- ‚úÖ Premiere XML Export
- ‚úÖ Learnings-System (Analyse ‚Üí Merge ‚Üí Nutzung)
- ‚úÖ Principle-based Approach
- ‚úÖ Batch-Verarbeitung
- ‚úÖ Conditional Processing
- ‚úÖ Multi-Level-Optimization (Stages 2.5-2.9)

## Was weg kann
- ‚ùå Alte Versionen (v1, v2 wo v4 existiert)
- ‚ùå Test/Debug Scripts die nicht mehr gebraucht werden
- ‚ùå Fix-Scripts die bereits angewendet wurden
- ‚ùå Backup-Dateien (au√üer wichtige)

## Wichtige Dateien
- `create_clips_v4_integrated.py` - Haupt-Pipeline (5500+ Zeilen)
- `SYSTEM_OVERVIEW.md` - Vollst√§ndige System-Dokumentation
- `PROJECT_HISTORY.md` - Vollst√§ndige Entwicklungs-History, alle Entscheidungen, Learnings
- `master_learnings_v2.py` - Learnings-Management
- `create_clips_v3_ensemble.py` - Consensus Engine
- `data/MASTER_LEARNINGS.json` - Zentrale Learnings-Datenbank

## Kosten-√úbersicht (pro 30-Minuten Video)
- **Stage 0:** $1.50 (Coarse Scan, pre-scored)
- **Stage 1:** $0.60 (Batch Refinement, 4 batches)
- **Stage 1.75:** $0.00 (Rule-based, keine AI)
- **Stage 2:** $0.30 (Conditional Restructure, nur ~60%)
- **Stage 2.5:** $6.00 (Viral Composition - Holistic Multi-AI, ersetzt Stages 2.5-2.9)
- **Godmode:** $0.80 (Batched Evaluation, 4 batches)
- **TOTAL:** ~$9.20 pro Video (vs. $12.65 vorher, 27% Reduktion durch Konsolidierung)

**Kosten pro viralem Clip:**
- Alt: $6.25-12.50 pro viral clip (10% Pass-Rate)
- Neu: $1.58-2.11 pro viral clip (40% Pass-Rate gesch√§tzt)
- **75% Verbesserung pro viralem Clip!**

## Dokumentation
- `SYSTEM_OVERVIEW.md` - Vollst√§ndige System-√úbersicht, alle Stages, Datenfluss
- `PROJECT_HISTORY.md` - Vollst√§ndige Entwicklungs-History, alle Entscheidungen, Fehlschl√§ge, Learnings
- `FUNCTION_SIGNATURES.md` - Alle Methoden-Signaturen
- `LEARN_FROM_VIRAL_EXAMPLE_OUTLINE.md` - Learnings-Prozess

## Key Insights
1. **Viral Clips werden komponiert, nicht nur gefunden** - Multi-Level-Optimization erforderlich
2. **Principle-based > Rigid Rules** - Anpassungsf√§higkeit ist kritisch
3. **Batch Processing = 80% Kostenersparnis** - Und bessere Qualit√§t!
4. **Multiple Gates erh√∂hen False Negatives** - Single Gate besser
5. **Kosten pro viral Clip > Kosten pro Video** - Wichtigerer Metric

## Aktuelle Herausforderungen
1. **Cost Creep:** $12.65 nahe am urspr√ºnglichen $12.50, aber bessere Qualit√§t
2. **Komplexit√§t:** 9 Stages = mehr Failure Points, schwerer zu debuggen
3. **Nicht production-getestet:** Nur Dieter Lange getestet, Generalisierung unklar
4. **Stage 2.9 fehlt:** Payoff Isolation noch nicht implementiert

## N√§chste kritische Schritte
1. **Stage 2.9 implementieren** (30-45 min)
2. **Full Pipeline Test** auf Dieter Lange ($12.65, validiere Scores)
3. **Diverse Content Tests** (5 Videos, $63.25)
4. **Hook Matching optimieren** (Batch statt Individual, $2.40 Savings)

---

**F√ºr vollst√§ndige History, alle Entscheidungen und Learnings ‚Üí siehe `PROJECT_HISTORY.md`**

